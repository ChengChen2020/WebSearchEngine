# Web Crawler

A (very primitive) multi-threaded web crawler in Python that attempts to do a limited crawl of the web.
- Learn about crawling
- Start programming in Python
- Learn a bit about the various structures and features found in web pages and how to handle/parse them

### What to submit
- 4 output logs
  - 2 queries
  - For each query you should do two runs, one for your prioritized crawl, and one using a simple BFS strategy.
- At least 10000 pages
- readme.txt
  - ASCII format
  - A list of the files in your submission and what they do, and with a short description on how to compile and run your program (meaning of input parameters, any configuration files etc.).
- explain.txt
  - a precise and succinct description of how the program works and 
   what the major functions are. Also, provide a list 
   of any bugs or non-working features in your program, 
   and disclose any additional resources that you used. 
   Finally, a list of any special features beyond the 
   basic requirements, if there are any.
- A gzipped tar file or a zip file with a directory CONTAINING your files. The directory should have the name "smith1" and the tar file should have the name "smith1.tar" if your last name is smith, and you are submitting your first homework.
